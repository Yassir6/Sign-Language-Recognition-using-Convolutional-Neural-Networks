
# Sign Language Recognition using Convolutional Neural Networks
## Backstory & scope
Sign language is the only way for deaf people to communicate with other individuals, not all individuals can understand sign language. which leads to, deaf people having a hard time communicating with others. Sign languages differ from language to language and in some cases from country to country. 

The goal of the project is to build a convolutional neural network that helps deaf people to communicate with others. The model that we are implementing can recognize a sign language from a picture then can predict the letter.

## Data
The data was imported from Kaggle website (Find the dataset on the following [link](https://www.kaggle.com/grassknoted/asl-alphabet/code)). Data contain more than 80,000 images. The images cover all English letters. Each letter has 3000 different images, images have been taken in different shapes, resolutions, lighting, and rotation.


## Algorithms

- Logistic Regression
- convolutional neural network(CNN)

Complex CNN with filters and early stop is the most accurate algorithm 



## Tools
- Pandas
- Sklearn 
- Matplotlib
- Tensorflow
- Keras
- numpy


## Communication
The project process and result has presented. To see the presentation slides click [here](https://github.com/Yassir6/Sign-Language-Recognition-using-Convolutional-Neural-Networks/blob/main/Sign%20Language%20Recognition%20using%20Convolutional%20Neural%20Networks.pdf).
